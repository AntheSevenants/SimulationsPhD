# The Oxford Handbook of Cognitive Linguistics

$public=true$

## Introducing cognitive linguistics

$p=3$

### Introduction

cognitive linguistics
- language as an instrument for **organising, processing and conveying information**

perspective
- formal structures of language are **reflections of general conceptual organisation**, categorisation principles, processing mechanisms and experiential and environmental influences

$p=4$

### The theoretical position of cognitive linguistics

topics of special interest
- natural language categorisation
- functional principles of linguistic organisation
- conceptual interface between syntax and semantics
- experiential and pragmatic background of language-in-use
- relationship between language and thought

$p=5$

$reader$
**Definition**

Cognitive Linguistics is the study of language in its **cognitive function**, where *cognitive* refers to the crucial role of the **intermediate informational structures** in our encounters with the world.
$/reader$

view on language
- language as a repository of world knowledge
- => structured collection of meaningful categories that help us deal with new experiences, and store information about old ones

----
$widec$
Three fundamental characteristics
$/widec$
----

1. the primacy of semantics in linguistic analysis
	- the basic function of language involves **meaning**
	- if the primary function is language is categorisation, then **meaning must be the primary linguistic phenomenon**
2. the encyclopedic nature of linguistic meaning
	- no need for a separate level of knowledge of the world -> encoded in language
3. the perspectival nature of linguistic meaning
	- the world is not objectively reflected in language

$p=25$

## Embodiment and experientalism

### Introduction

----
$widec$
How does language work?
$/widec$
----

==**Objectivist** tradition==
- meaning is something **abstract**, propositional and symbolic
- semantics is purely referential, syntactic structures resolve to **logical relations**

$p=26$

==**Cognitive** tradition==
- utterances (and meaning) are embedded within a **cognitive and social situation**
- semantics beyond the purely referential, also for communication and shared experiences

$p=27$

### The senses of embodiment

embodiment
- "human physical, cognitive, and social embodiment ground our conceptual and linguistic systems"
- <-> generativist: language system as something detached and abstract (nvda.)

$p=48$

## Construal and perspectivisation

### Introduction

semantics in cognitive linguistics
- **cognitive** -> not simply a medium between language and the world (or truth conditions *about* the world)

$widec$
$down
$/widec$

==construal==
- term used for **different ways of viewing a particular situation**
- a feature of the meaning of all linguistic expressions

$p=49$

$reader$
A speaker who accurately observes the spatial distribution of certain stars can describe them in many distinct fashions: as a *constellation*, as a *cluster of stars* as *specks of lights in the sky*, etc. Such expressions are semantically distinct; **they reflect the speaker's alternate construals of the scene**, each compatible with its objectively given properties. (Langacker 1990a: 61)
$/reader$

$result many different ways of looking at the world
- depends on knowledge of the world, focus (collective stars, individual stars ...)

$p=63$

### Perspectivisation

perspectivisation
- having the relation between the ground and the object of conceptualisation profiled in the **interpretation of the utterances**
- e.g. *The ballroom is below.* -> grounding in the actual utterance itself

$p=82$

## Schematicity

### Introduction

$p=83$

### The nature of schematicity

#### The basic idea

_schema_
- a superordinate concept
- specifies the basic outline common to several, or many, more specific concepts

$result *elaborations* / *instantiations* / *subcases*
- fill in the schema or outline

#### Langacker's characterisation

ability to generalise
- ~= extraction of schemas
- "one of the most central human cognitive capabilities"
- ability to abstract less important details

$p=84$

hierarchy
- schemas can exist relative to each other
- i.e. organised with arrows ("->")

#### Lakoffian "Image Schemas"

image schemas
- "relatively simple structures that constantly recur in our **everyday bodily experience**"
- e.g. <span class="feature">containers</span>, <span class="feature">paths</span>, <span class="feature">links</span>, <span class="feature">up-down</span>, <span class="feature">front-back</span>, etc.

$p=85$

difference with Langacker's schemas
- Lakoff schemas are *central truths*, not many Langacker schemas will be Lakoffian schemas

### The ubiquity of schematicity

ubiquity of schematicity
- present in every langauge
- every language will have some concepts which are relatively specific, and others which are about the same but _less_ specific

$p=117$

## Entrenchment, salience and basic levels

### Introduction

human capacity to process language
- closely linked with / determined by other fundamental cognitive abilities
	- e.g. perception, memory, attention allocation
- these mechanisms **influence the storage of concepts and constructions in long-term memory**
- also: how concepts and constructions are **retrieved and activated** from memory during **language processing**

$p=118$

### The notions of *entrenchment* and *salience* in cognitive linguistics

#### Entrenchment

==competence==
- the **linguistic knowledge** of phonological, semantic, grammatical and collocational properties of words and syntactic structures
- stored in **long-term memory**

$wide$
- $result used when speakers encode their conceptualisations in words and sentences
$/wide$

[ Views on encoding / decoding ]
|generative view|cognitive view|
|---|---|
|language users **actively search memory for means of encoding** what's on their mind|much of what speakers say is available in memory in **prepackaged format**|

$reader$
Convincing evidence for this claim are the words
of a language, since these represent nothing else than **conceptualizations that have
been fossilized by convention in a speech community**. We hardly ever stop to think
what language would be like without prepackaged concepts readily encodable by
words. To refer to a dog that we see running across a meadow, there is no need to
consciously construe an appropriate conceptual unit from scratch, because words
like _dog_ or _poodle_ are readily available. The question of how to name this entity will
not reach a level of conscious awareness, and the activation of concepts matching
our experience of the dog will hardly require cognitive effort. The reason is that
**familiar concepts like ‘dog’ or ‘poodle’ are deeply entrenched in our memory so
that their activation has become a highly automated routine**.
$/reader$

$result ==entrenchment==
- ==the degree to which the formation and activation of a cognitive unit is routinised and automated== (p. 119)
- "fostered by repetitions of cognitive events" (Langacker 187 : 100) -> **correlates with frequency of use**

$p=119$

$info$
Geeraerts, Grondelaers, and
Bakema (1994) argue for a more refined version of this idea (see section 5). On their
account, it is **not frequency of use as such that determines entrenchment**, but **frequency of use *with regard to a specific meaning or function in comparison with alternative expressions of that meaning or function***.
$/info$

$result entrenchment on a **group level**
- can also be a collective phenomenon through **collective automatisation**
- => entrenchment of a concept or construction **in a given language**

#### Salience

----
$widec$
Salience has two interpretations in Cognitive linguistics
$/widec$
----

$p=120$

[ Cognitive salience <-> ontological salience ]
|cognitive salience|ontological salience|
|---|---|
|a temporary activation state of mental concepts|an inherent and consequently more or less permanent property of entities in the real world|

$p=119$

##### Cognitive salience

==cognitive salience==
- the activation of concepts in **actual speech events**
- can be the result of two mental processes

$widec$
$down
$/widec$

$acco$
**1.** conscious selection mechanism
- cognitive units activated because a concept enters a person's focus of attention
- therefore: processed in current working memory (Anderson 1983: 118–20; Deane 1992: 35)

**2.** activation of one concept facilitates activation of others
- e.g. 'dog' -> ‘bark’, ‘tail wagging’, ‘fur’, ‘poodle’, ‘alsatian’, ‘collie’, etc.
- (see Collins and Quillian 1969;
Collins and Loftus 1975; Anderson 1983: 86–125; and Deane 1992: 34)
$/acco$

$result salient
- a cognitive unit is *salient* if it has been loaded (in working memory, for whatever reason)

$info$
Since the use of **concepts that are already activated requires
minimal cognitive effort**, a **high degree of cognitive salience correlates with ease of
activation** and little or no processing cost. Currently **inactive concepts,** on the other
hand, **are nonsalient**.
$/info$

$p=120$

##### Ontological salience

==ontological salience==
- related to more or less **stable properties of entities in the world**
- **some entities** are, by nature, **better qualified to attract our attention** than others
- => some entities can be 'more salient' in this way

$result link between cognitive and ontological salience
- mental concepts of salient entities have a **better chance of entering our focus of
attention**
- => ontologically salient entities are more likely to evoke
corresponding cognitively salient concepts than ontologically nonsalient ones

$example$
For
example, **a dog has a better attention-attracting potential than the field over which
it is running**. Therefore, it is **likely that observers of the scene will be more aware of
the dog and its actions than of the field**.
$/example$

##### Relation between salience and entrenchment

$acco$
1. **==ontologically salient entities attract our attention more frequently==** than non-salient ones
	- cognitive events related to the processing of **ontologically salient entities** will occur **more frequently**
	- leads to **earlier entrenchment** of corresponding cognitive units, or concepts

$example$
This is perhaps most noticeable **in the early stages of language acquisition when
active, movable, or otherwise interesting—and therefore salient—entities** such as
people, animals, or colorful and noisy toys, which have a relatively high potential of
attracting children’s attention, **stand a better chance of early entrenchment as cognitive units** than less salient entities, such as walls or carpets. 
$/example$

$info$
**There is no one-to-one causal link between ontological salience and
entrenchment**, because from a certain point onwards, children acquire the ability
of adults to conceptualize one entity, say a given dog, via a whole range of differently entrenched concepts such as ‘dog’, ‘poodle’, ‘mongrel’, ‘animal’, or ‘creature’.
This shows that it is, of course, not real-world entities themselves that get entrenched but **possible _concepts_ of entities**.
$/info$
$/acco$

$acco$
2. ==**deeply entrenched cognitive units are more likely to become cognitively salient**== than less well entrenched ones
	- a smaller amount of spreading activation will suffice to activate them
$/acco$

$p=121$

### The role of entrenchment in the emergence, sanctioning and blocking of linguistic units

entrenchment
- the storage of **concepts and constructions** as **routinised items** in long-term memory

$result function as Gestalts
- an **entrenched unit functions as a single form**
- its subparts still exist, but they become less salient (the speaker no longer has to attend to them individually)
- => cognitively **easier to process** and manipulate these structures

beyond the lexical dimension
- collocational patterns / constructions / syntactic structures are **also entrenched**

$example$
- _I don’t know_, _I don’t think_, _do you want_, or _and I said_ (Biber et al. 1999: 994)
- clause patterns such as ‘abstract NP as subject + copula + _that_-clause’ (e.g., _the thing_/_fact_/_point_/_problem is
that_ . . . ) or ‘abstract NP as subject + copula + _to_-infinitive’ (e.g., _the aim_/_job_/_task_/
_idea is to_ . . . ; see Schmid 2000)
$/example$

#### Emergency and sanctioning

*sanctioning*
- firmly entrenched units play a crucial role in the emergence of **novel** linguistic structures

$info$
If the way to the establishment of novel structures in the repertoire of individual speakers and in the lexicon and grammar of a
language is paved by **similar structures that are already well entrenched**, their
entrenchment (i.e., of these **novel structures**) will be **facilitated** in turn.
$/info$

#### Blocking

blocking
- well-entrenched structures can inhibit or block the adoption of novel structures (Langacker 1991: 162)
- e.g. in word formation -> novel concept is already too well established!

$example$
The entrenchment of potential novel structures like English
\*_stealer_ or German \*_Bauer_ (as a derivation of the verb _bauen_ ‘build’) is blocked by
the established words _thief_ and _Bauer_ ‘farmer’ respectively.
$/example$

$p=122$

### Salience and entrenchment effects in the lexicon: basic levels of categorisation

effect of spreading activation
- many **more words than those that
are uttered** in a given speech act are activated during the process of lexical retrieval

$result supported by **association and priming experiments**
- whole **networks of concepts** that can be related to a target word in various 
ways achieve **some level of activation** during lexical retrieval (Aitchison
2003: 84–101)
- e.g., synonyms, antonyms, superordinates, subordinates, collocates, elements of one frame

$widec$
$down

conceptual organisation may involve two levels of activation
$/widec$

1. activation of a **conceptual network**
2. activation of the **active node** from the options provided by the network

$wide$
- $result idea: **well-entrenched concepts** have a **better chance of being selected as active nodes** than less well-entrenched ones
$/wide$

$p=124$

basic-level category
- a general category of deeply entrenched items that are not *too specific* but also not *too general*
- acquired early

$p=139$

## Polysemy, prototypes and radial categories

### Introduction

polysemy
- some words having more than one meaning, and these meanings being related

$p=140$

polysemy in Cognitive Linguistics
- polysemy as a **form of categorisation**

$p=141$

### Polysemy tests and the flexibility of meaning

#### The logical test

$p=142$

#### The linguistic ambiguity test

$p=143$

#### The definitional test

$p=144$

### Prototype theory

flexible meaning
- not: meaning through binary features / 'necessary conditions'
- => **analog structure**

$p=145$

#### Prototype effects

----
$widec$
Frequently mentioned features of prototype-theoretical conception
$/widec$
----

1. Prototypical categories exhibit **degrees of typicality**; **not every member is
equally representative** for a category.
1. Prototypical categories are **blurred at the edges**.
1. Prototypical categories **cannot be defined by means of a single set of** criterial (necessary and sufficient) **attributes**.
1. Prototypical categories exhibit a **family resemblance structure**, or more
generally, their semantic structure takes the form of a radial set of clustered
and overlapping readings.

$p=152$

### Schematic networks

#### Parsimony or polysemy?

cognitive linguistics view on polysemy
- each lexical meaning is an access point to a *network* of related categories

$p=154$

schematic network model
- introduces different levels of abstraction into the mode

$p=170$

## Frames, idealised cognitive models, and domains

### Introduction

structure of knowledge
- frames, Idealised Cognitive Models (ICMs) and domains
- all derive from an approach to **language as a system of communication that reflects the world as it is construed by humans**

### Frames

$p=172$

scene
- a **standard scenario** (i.e. defined by culture)

frame
- any system of **linguistic choices**
- i.e. collections of words, choices of grammatical rules or linguistic categories that can be associated with prototypical instances of scenes

$p=175$

### Idealised cognitive models

$p=176$

idealised cognitive models (ICMs)
- a way in which we **organise knowledge**
- not as a direct reflection of an objective state of affairs in the world, but **according to certain cognitive structuring principles**
- *idealised* -> involve an abstraction through perceptual and conceptual processes
- impose **structure**, e.g. in the form of conceptual categories

$result evolutionary advantage
- structures adapted to human perception are evolutionary advantageous

$p=177$

ICM
- can serve as a background for a specific word

$p=181$

### Domains

==domain==
- "a **coherent area of conceptualization** relative to which semantic units may be characterized" Langacker (1987: 488)
- **provide the scope of concepts** relevant for characterising the meanings of linguistic units

$p=182$

[ Types of domains ]
|basic domain|abstract domain|
|---|---|
|a domain that cannot be fully reduced to any other domains|a domain that defines a higher-order concept|
|e.g. *elbow* requires knowledge about domain of *arm*|e.g. *up*, *down* (~= schema)|
|have one or more dimensions|???|

[ Two types of domains ]
|locational domain|configurational domain|
|---|---|
|defined by a location on one or more scales|can accommodate a number of distinct values as part of a single gestalt|
|e.g. temperature, colour|e.g. multi-dimensional domains|

$p=214$

## Image schemas

### Introduction

$p=215$

image schema
- a condensed **redescription of perceptual experience** for the purpose of **mapping spatial structure onto conceptual structure**
- => 'distillers' of spatial and temporal experiences

$info$
Accordingly, going to the
library and getting a book can be conceptually grouped with a number of instances
with little in common save for exhibiting the same image-schematic structure.
$/info$

### Preliminary distinctions

#### Schemas, images and image schemas

$p=216$

----
$widec$
Historical definitions
$/widec$
----

$acco$
schema
- a fixed template for ordering specific information

$avs$
**University Library**

librarian
: &lt;slot&gt;

patron
: &lt;slot&gt;

student
: &lt;slot&gt;

faculty
: &lt;slot&gt;
$/avs$
$/acco$

$acco$
image
- a representation of specific patterns capable of being rendered schematically

$reader$
Concepts
(even abstract concepts) develop from representations of a perceptual conglomeration of visual, auditory, haptic, motoric, olfactory, and gustatory experiences.
Images are always analogue representations of specific things or activities
$/reader$
$/acco$

$widec$
$down
$/widec$

$p=217$

image schema
- highly flexible preconceptual and **primitive patterns** used for
reasoning in an array of contexts (Johnson 1987: 30)

$example$
For instance, going to the library fits the following image-schematic profile: <span class="feature">source-path-goal—container—collection—part-whole—transfer—
iteration</span>. The library exists as the end point to a path. It also has an inside and an
outside, and thus is capable of containing people and objects. Since the objects it
contains are of the same kind, the library exploits the notion of collection, which
piggybacks on the opposition between part and whole. Physically possessing one of
these contained objects in the collection exploits the transfer schema, and its repeatability exploits the iteration schema. The above profile represents some of the
most conceptually assessable schemas used to structure a working notion of library.
$/example$

$p=421$

## Cognitive grammar

### Background

#### What is cognitive grammar?

cognitive grammar
- *not* derived from any other theory

shared properties with construction grammar
- ~~rules~~ -> **constructions** are primary objects of description
- lexicon and grammar are *not* distinct -> rather a **continuum of constructions**
	- these are linked in networks of **inheritance**

$p=422$

[ Differences between cognitive linguistics and construction grammar ]
|cognitive linguistics|construction grammar|
|---|---|
|**construal** deemed **important**|**ignores construal** factors|
|all valid grammatical constructs have a **conceptual characterisation**|grammatical constructs (nouns, verbs, subjects) treated as **unanalysable syntactic primitives**|

functional cognitive grammar
- language is **symbolic** -> allows conceptualisations to be symbolised by sounds and gestures
- language is **communicative/interactive** -> all linguistic units are abstracted from **usage events**

'cognitive' in cognitive linguistics
- language as an **integral fact of cognition** -> not a separate module (<-> generative grammar)
- recruits more **general cognitive phenomena** (e.g. attention, perception, categorization, memory)

#### The levels of cognitive grammar

----
$widec$
Cognitive grammar has a language structure of **three independent levels**
$/widec$
----

**1.** descriptive framework
- allows for the explicit characterisation of the **full range of linguistic structures** encountered empirically
- *even* the most unusual structures -> needs a **flexible structure**
- => large space of structural possibilities

**2.** universal / prototypical structures
- what general structures do we see in the world's languages?
- on the basis of cross-linguistic surveys

$p=423$

**3.** functional explanations
- why the findings of levels **1** and **2**?

#### Principles

----
$widec$
Several **principles** in the description of linguistic structure
$/widec$
----

$acco$
**1.** functional considerations
- **pervasive** in the framework architecture and descriptive apparatus
$/acco$

$acco$
**2.** required detail and technical precision
- structures need to have 'apt detail', yet be 'natural and appropriate' (very vague)
$/acco$

$acco$
**3.** language and languages have to be descripted **in their own terms**
- no imposition of artificial boundaries or 'Procrustean modes of analysis'
- formalisation is not to be considered an end in itself -> must be **useful** for the analysis

$info$
That no attempt has yet been
made to formalize Cognitive Grammar reflects the judgment that the cost of the
requisite simplifications and distortions would greatly outweigh any putative benefits.
$/info$
$/acco$

$acco$
**4.** compatibility with related disciplines
- laims about language should be broadly
compatible with secure findings of related disciplines
- e.g. cognitive psychology, neuroscience, and evolutionary biology
$/acco$

#### Positioning of Cognitive Grammar

----
$widec$
Widely accepted Cognitive Grammar claims
$/widec$
----


$wide$
- prototype categorization
- conceptual semantics
- the semantic basis of most grammaticality judgments
- the inseparability of grammatical and semantic analysis
- lexicon and grammar forming a continuum
- constructions as the primary objects of description
- inheritance network
- 'rules' as schemas (or templates)
- a nonderivational ('monostratal') view;
- well-formedness as simultaneous constraint satisfaction
- composition as 'unification'
- a 'usage based' model
$/wide$

----
$widec$
Unique / notorious claims
$/widec$
----

$wide$
- the conceptual characterisation of basic grammatical notions (e.g. noun, verb, subject, object)
- the full reduction of lexicon and grammar to assemblies of symbolic structures
$/wide$

----
$widec$
Conservative / down-to-earth facts of Cognitive Grammar
$/widec$
----

$wide$
- reflex **not to invoke any cognitive phenomena that are not well known or easily demonstrable**
- strategy to seek converging evidence from **three independent sources**
	1. construct must be **cognitively plausible**
	2. construct must **prove necessary** for describing and distinguishing meanings
	3. construct must **'play a rule in grammar'** (whatever *that* means)
$/wide$

$p=424$

----
$widec$
Content requirements
$/widec$
----

1. limits the linguistic units one can posit to ==semantic structures==, ==phonological structures==, and ==symbolic structures== (which pair the other two)
2. the units posited must either be ==part of the primary data== (occurring expressions) or else be ==derivable from it via the basic psychological processes of schematization and categorization==.

### Architecture

#### What is language?

language in Cognitive grammar
- a **structured inventory of conventional linguistic units**

$result *unit*
- a pattern of processing activity
- thoroughly mastered, can be carried out more or less automatically
- => **cognitive routine**

$result *inventory*
- framework is **non-generative** and **non-constructive**
- linguistic units do _not_ constitute an autonomous derivational system itself responsible for constructing well-formed expressions
- => a collection of resources that speakers can exploit

$result *structured*
- not discrete and separate -> units **relate** to one another in various ways
- overlap, inclusion, symbolisation, categorisation, integration into higher-level units

$p=425$

#### Linguistic processes

becoming a unit
- happens through **progressive psychological *entrenchment***
- a matter of 'degree' (how entrenched is a unit?)

shared units
- *conventionality* -> how widely is a structure shared and accepted among speakers?
- a matter of 'degree' (how conventional is a unit among language users?)

*usage event*
- an actual **instance of language use**
- have conceptualisation, full contextual understanding, expression, phonetic and gestural detail ...
- _all_ linguistic units are abstracted from these events

$result abstraction?
- a matter of reinforcing whatever **commonalities** occur across a number of usage events
- features which do _not_ recur fail to be reinforced and are therefore **filtered out**
- => all linguistic units are selective and schematic vis-à-vis the usage events from which they arise

#### Structures relevant to discourse

----
$widec$
Any facets of a usage event, or a sequence of events in a discourse, are susceptible to being abstracted and conventionalised as a unit
$/widec$
----

$p=426$

$gallery$
**Structures relevant to discourse**

![Image](img$ki1j)

$widec$
(Langacker 2001a)
$/widec$
$/gallery$

$p=425$

$result *ground*
- comprises: ==speaker (S)==, ==hearer (H)==, their ==interaction (<->)== and their ==immediate circumstances==

$result *viewing frame*
- general locus of viewing ==attention (->)== (metaphorically)
	- conceptual analogue of the visual field
- subjective 'space' within which a conceptualisation is manifested

$result *focus*
- the focus of attention

$result *context*
- the larger context

$result *shared knowledge*
- the body of knowledge presumed to be shared by speaker and hearer

$result *current discourse space*
- the mental space comprising whatever is shared by the speaker and hearer as a basis for communication at a given moment in the flow of discourse

$p=426$

#### Channels
$p=427$

$gallery port$
$widec$
![Image](img$nk3e)
$/widec$

$widec$
==conceptualisation== and ==expression== can each be resolved into a number of **channels**
$/widec$
$/gallery port$

$p=426$

$widec$
$down
$/widec$


$result _objective situation_
- the conception of the situation being discussed

$result _segmental content_
- segmental phonological content

#### The abstraction process

abstraction
- unit reflects a **recurring usage configuration**
- makes specifications in certain sectors, but remains unspecified (or maximally schematic) in regard to others

$info$
A unit’s conventional import with respect to various factors often excluded from the scope of linguistic
description (e.g., **register, affect, discourse function, relative social status of the interlocutors**) is **also specified in sectors not focused in the viewing frame**.
$/info$

#### Global facets of units

$p=427$

[ The global facets and their correspondence ]
|conceptualisation|expression|
|---|---|
|semantic pole|phonological pole|
|central and significant channels of conceptualisation\*|comprises all channels of expression|

$info$
\* Conceived more broadly, however, the semantic pole includes all the sectors in figure 17.1 (the first picture), regardless of specificity. It
is even taken as subsuming the channels of expression, on the grounds that these are
also apprehended and for various purposes are advantageously treated as facets of
conceptualization (Langacker 1987a: section 2.2.1)
$/info$

#### Three types of units

*semantic units*
- units that only have a semantic pole (in the narrow sense)

*phonological units*
- units that only have a phonological pole
- e.g. a phoneme or phonotactic pattern

*symbolic unit*
- units that have both a semantic and phonological pole

$info$
These three types of units are the minimum needed for language to fulfil its symbolic function.
$/info$

$info$
A central claim -- embodied in the content requirement -- is that **_only_ these are necessary**. Cognitive
Grammar maintains that **a language is fully describable in terms of semantic structures, phonological structures, and symbolic links between them**. Linguistic units are further limited to those arising from occurring expressions via schematization and categorization.
$/info$

$widec$
$down
$/widec$

lexicon and grammar
- a **continuum** of **symbolic structures**

$result lexicon
- the set of **'fixed' expressions** in a language
- conventional expressions with the status of units
- two parameters: *specificity* and *symbolic complexity* ($see $down)

##### Specificity and symbolic complexity

*specificity*
- how schematic is the expression? (e.g. _hammer_ > *tool* > *thing*)

*symbolic complexity*
- how many consecutive symbolic elements does it contain? (e.g. *sharp* < *sharpener* < *electric sharpener*)

$p=428$

$info$
Imposing any particular line of demarcation would
be **arbitrary**. Thus, the highly schematic meanings of 'grammatical' elements --
such as the infinitival _to_, the preposition _of_, or the auxiliary verb _do_ -- do not
prevent them from also counting as lexical items. Nor is lexicon limited to words,
compounds, and short phrases. Provided that they are learned as conventional
units, **expressions of any size qualify as lexical items**
$/info$

##### Subcategorisation

----
$widec$
Using _specificity_ and _symbolic complexity_ to categorise units
$/widec$
----

|category|semantic dimension|phonological specificity|symbolic complexity|
|---|---|---|---|
|lexical items|specific|specific|non-complex|
|grammatical markers|schematic|specific|non-complex|
|'noun' and 'verb' categories|schematic|schematic|underspecified|
|grammatical rules / combinatory patterns|schematic|scehmatic|complex|

$info$
If symbolic structures are _schematic_ rather than _specific_, they tend to be regarded as _grammatical_ rather than _lexical_ (e.g. grammatical *do*).
$/info$

$info$
Among the further resources employed are general
and contextual knowledge, basic cognitive abilities (e.g., memory, attention, planning,
aesthetic judgment), as well as such 'imaginative' capacities as metaphor, blending,
mental space construction, and the evocation of 'fictive' entities (Talmy 1996;
Langacker 1999d). Linguistic units themselves reflect such factors internally. These
same factors figure as well in the formation of novel expressions, which thus incorporate many features not solely derivable from the linguistic units invoked.
$/info$

##### Categorisation

linguistic knowledge
- bound up with other resources, exploited in a dynamic processing system
- resides in routinised 'packets' of processing activity

$p=429$

$gallery$
**Coding**

$widec$
![Image](img$7ooe)
$/widec$

$widec$
==**L:** linguistic system==
==**U:** usage event==
$/widec$

$widec$
unit **A** (from L) is activated, effecting the categorisation of structure **B**
$/widec$

[ Two types of possibilities ]
|full manifestation|partial / imperfect manifestation|
|full arrow|dashed arrow|
|---|---|
|A is fully manifested in B|A is partially manifested in B|
|the target **conforms to the conventional unit** invoked|the target **distorts the conventional unit** in some manner|
|categorising relation of *elaboration*|categorising relation of *extension*|
$/gallery$

categorisation / *coding* (1987a)
- happens when a unit is strongly activated as part of an expression's apprehension

$info$
I think the confirmation / distortion is related to how well it fits a certain category (one of the features which construction grammar has, where there are no exceptions).
$/info$

##### Selecting units for the categorisation of usage events

$gallery$
**Activation of categorising units**

![Image](img$bvd5)

$widec$
==**T:** potential _target_ of categorisation== (some facet of an incipient usage event)  
$result on the basis of overlapping features, **T** tends to activate a set of units each of which has the _potential_ to categorise it  
$result = *activation set* in (a) -> all members are initially activated to some degree
$/widec$

$widec$
all units of activation set stride for categorisation of **T**  
$result contributing factors:  degree of entrenchment (inherent ease of activation), contextual priming, and extent of overlap with the target
$/widec$
$/gallery$

$reader$
How are units selected for the categorization of usage events? At the processing phase when linguistic units are still being recruited for exploitation, a usage event
is only incipient. Before the units employed are selected and fully activated, neither
the conceptualization nor the vocalization has yet been fully developed and structured in accordance with their specifications. **It is precisely the activation of a particular set of units that results in a full-blown usage event interpreted as manifesting
a particular linguistic expression**. 
$/reader$

##### Multiple categorisations

$reader$
A usage event
is simultaneously **categorized by _many_ conventional units**, each pertaining to a
particular **facet** of its structure.
$/reader$

event's *structural description*
- constituted by categorisations

$p=430$

$widec$
$down
$/widec$

$acco$
all categorisations effected on a given occasion are **elaborative**
- the expression is fully well-formed
$/acco$

$acco$
some categorisations effected on a given occasion are **extensive**
- there is a degree of non-conventionality ('ill-formedness')
- however: a **certain degree of non-conventionality is normal**

$warn$
It is only when the distortions are **drastic** enough
(individually or collectively) that an expression is judged as being **deviant**.
$/warn$
$/acco$

$gallery$
|coding|extension|
|---|---|
|![Image](img$7ooe)|![Image](img$mqeo)|

$widec$
$result unit **A** is employed for the categorisation of **B**, in the context of a single usage event  
$result unit **B** represents the contextual value assumed by **A** on that occasion
$/widec$

$reader$
Suppose, now, that **A is used with comparable value on a number of occasions**
(e.g., a lexical item might be used repeatedly with the same extended meaning). If
both B and B’s categorization by A occur across a series of usage events, they—like
any other facet of such events—are subject to **progressive entrenchment** and **conventionalization**. The result, as shown for the case of extension in figure 17.5 (on the right), is that
**both achieve the status of conventional linguistic units** and are thus **incorporated
in the linguistic system** (as a matter of definition).
$/reader$

$reader$
Starting from a single unit, A,
successive developments of this sort can eventually yield a **network of related units**
linked by categorizing relationships (which can themselves be recognized as units). This network is a **_complex category_**, with A as its **_prototype_** (Lakoff 1987; Langacker 1987a: chapter 10; Taylor 1995).
$/reader$
$/gallery$

$widec$
$down

this is how linguistic units maintain themselves and evolve!
$/widec$

$acco$
activation of a unit
- reinforces and further entrenches that unit

lack of activation of a unit
- causes the unit to 'decay' / eventually be lost
$/acco$

$acco$
elaboration
- a unit is further strengthened

extension
- the definition of a unit it expanded
$/acco$

$reader$
Thus, every instance of language use has some
**impact**, however slight, on the linguistic system as currently constituted. In this
_usage-based_ perspective (Barlow and Kemmer 2000), **synchrony and diachrony are
inseparable**.
$/reader$

$p=431$

### Semantics

----
$widec$
Central claim of Cognitive Grammar: only symbolic structures (form-meaning pairings) need be posited for the characterisation of lexicon and grammar  
$down  
form a **continuum**
$/widec$
----

$wide$
- $result elements, structures, and constructs employed in grammatical description must all be **meaningful** (just as lexical items are)
$/wide$

#### Conceptualist semantics

==conceptualisation==
- encompassing *any kind of mental experience*
	1. both established and novel conceptions
	2. not only abstract or intellectual 'concepts', but also immediate sensory, motor, kinaesthetic, and emotive experience
	3. conceptions that are not instantaneous, but change or unfold through processing time
	4. full apprehension of the physical, linguistic, social, and cultural context

$widec$
I'm skipping this, as it seems vague and not very relevant to me
$/widec$

$p=438$

### Grammar

#### Continuum

----
$widec$
lexicon --------------------------> grammar

continuum of *assemblies of symbolic structures*
$/widec$
----

any assembly
- can exhibit **any degree of symbolic complexity **and **any degree of semantic and phonological specificity or schematicity**
- $see $up

$p=439$

#### Semantic character of grammatical classes

----
$widec$
Cognitive Grammar claims: basic grammatical classes can be characterized **semantically**
$/widec$
----

$acco$
**1.** only applies to a limited set of categories
- these categories are useful in describing...
	1. many (if not all) languages
		- e.g. 'noun' and 'verb', their major subclasses (e.g. 'count' and 'mass'), 'adjective', 'adverb', and 'adposition'
	2. numerous phenomena in a single language
		- e.g. idiosyncratic classes reflecting a single language-specific phenomenon (e.g. red and green order in Dutch and lexical preferences)
$/acco$

$acco$
$wide$
**2.** reference to traditional parts of speech is selective and qualified
$/wide$

$reader$
The traditional scheme is highly problematic, and of the standard
classes only noun and verb correspond to fundamental Cognitive Grammar categories. To some extent the others do, however, have a semantic rationale, which Cognitive Grammar notions allow one to explicate. But in each case a new conceptual
description is offered which defines the class in its own, nonstandard way.
$/reader$

$widec$
I'm skipping the philosophical distinction between noun and verb as it's not relevant to me at this stage
$/widec$
$/acco$

$p=441$

#### View on grammar

grammar
- consists of **combinatory patterns** for assembling **symbolically complex expressions made out of simpler ones**

morphology <-> syntax
- just a matter of whether or not the expression formed is larger than a word (e.g. _admirer_ <-> _do admire_)
- otherwise no sharp distinction between them -> the same basic principles apply to both

$reader$
A particular
complex expression consists of an assembly of **symbolic structures, each phonologically specific**. The constructional schemas describing their formation consist of
symbolic assemblies where **some or all of the structures are both semantically and
phonologically schematic**. Constructional schemas categorize (and are immanent
in) instantiating expressions, just as class schemas are.
$/reader$

$gallery port$
**Constructions (p. 442)**

$widec$
![Image](img$k0lo)
$/widec$

$result symbolic structures are connected (and form assemblies) by *correspondences* and relationships of categorisation

$reader$
A specific example, sketched in figure 17.9, is the nominal expression _the table near
the door_. Correspondences are given as dotted lines. They indicate how symbolic
structures conceptually overlap by invoking entities construed as being the same.
The arrows for elaboration and extension (solid and dashed, respectively) indicate
that certain symbolic structures (or substructures thereof) are fully or partially
immanent in others and thus contribute to their emergence. In particular, what is
traditionally thought of as semantic and grammatical ‘‘composition’’ is viewed in
Cognitive Grammar as a matter of categorization. Two levels of composition are
shown in figure 17.9. At the ‘‘lower’’ level, two component structures, _near_ and
_the door_, categorize the composite structure, _near the door_. At the ‘‘higher’’ level, the
component structures _the table_ and _near the door_ categorize the overall composite
structure, _the table near the door_. Observe that _near_ is schematic with respect to
_near the door_, and _the table_ with respect to _the table near the door_. On the other
hand, _near the door_ constitutes an extension vis-à-vis _the door_, and _the table near the
door_ vis-à-vis _near the door_, owing to discrepancies in the nature of their profiles.

At a given level of organization, ‘‘horizontal’’ correspondence lines specify
which facets of the component structures conceptually overlap and thus project to
the same substructure at the composite structure level. Here the landmark of _near_
corresponds to the profile of _the door_, which ‘‘unify’’ to form the composite conception. At the higher level, the trajector of _near the door_ corresponds to the profile
of _the table_. It is typical for one component structure to contain a schematic
element which corresponds to the profile of the other component and which is
elaborated by this component. This schematic substructure is called an elaboration
site (_e-site_), marked by hatching. The horizontal arrows thus indicate that _the door_
elaborates the schematic landmark of _near_, and _the table_ the schematic trajector of
_near the door_. It is also typical for one component structure to impose its own
profile at the composite structure level. Thus, _near_ contributes its profile to _near
the door_ (which profiles the relationship of proximity, not the door), and _the table_
to _the table near the door_ (which profiles the table). Called the _profile determinant_,
the prevailing component is marked with a heavy-line box.
$/reader$
$/gallery port$

$p=442$

$reader$
Symbolic assemblies exhibit _constituency_ when a composite structure (e.g., _near
the door_ in figure 17.9) also functions as component structure at another level of
organization. **In Cognitive Grammar, however, grammatical constituency is seen as
being variable, nonessential, and nonfundamental.** An expression can have the same
composite structure and the same grammatical relationships, with alternate orders of
composition (or even a totally ‘‘flat’’ structure). The information essential to grammar 
does not reside in constituency but in the semantic characterizations of symbolic
structures and how these relate to one another. A structure’s grammatical class is
inherently specified by the nature of its profile. Various other aspects of grammatical
organization inhere in relationships of correspondence and categorization.
$/reader$

$widec$
again, skipping ...
$/widec$

$p=443$

### Phonology

$p=445$

usage-based phonology
- phonological units are **abstracted from usage events** by the **reinforcement of recurring commonalities**
- multiple units are abstracted, representing various levels and dimensions of schematisation
- => organised in complex categories, centred on **prototypes**

$p=463$

## Construction grammar

### Introduction: the revival of constructions

construction grammar's basic principle
- the basic form of a syntactic structure is a **construction**

$widec$
$down
$/widec$

==_construction_==
- pairing of a complex **grammatical structure** with its **meanings**
- organised in a **network**!
- generalised to all grammatical knowledge: syntax, morphology and lexicon

$p=464$

### Arguments for construction grammar

#### The componential model

$acco$
==componential model== of organisation of grammar
- the 'adversary' of construction grammar
- found in generative syntactic theories

properties of componential model
- different types of properties of an utterance are represented in **separate components**
	- each of which consists of rules operating over primitive elements of the relevant
types (phonemes, syntactic units, semantic units)
- e.g. sound structure, syntax, meaning ... all operated independently

$reader$
**Independent operation**

1. The **phonological component**, for example, consists of the rules and constraints governing the sound structure of
a sentence of the language.
2. The **syntactic component** consists of the rules and constraints governing the syntax—the combinations of words—of a sentence. 
3. The **semantic component** consists of rules and constraints governing the meaning of a
sentence.

=> In other words, **each component separates out each specific type of linguistic information that is contained in a sentence**: phonological, syntactic, and
semantic.
$/reader$

$reader$
**Syntactic component: further structure**

In addition, all versions of Chomskyan Generative Grammar have **broken
down the syntactic component further**, as **levels** or **strata** (such as ‘‘deep structure,’’
later ‘‘D-structure,’’ and ‘‘surface structure,’’ later ‘‘S-structure’’; Chomsky 1981)
and modules or theories (such as Case theory, Binding theory, etc.; Chomsky 1981).
$/reader$
$/acco$

$result general principle
- each component governs linguistic properties of a single type -- sound, word structure, syntax, meaning, and use

$result lexicon component
- only exception -> **words** contain information which cuts across the different components
- conventional associations of phonological form, syntactic category *and* meaning
- also: syntactically atomic (as the minimal syntactic units)

$p=465$

$resut linking rules
- 'rules' tying the different levels together
- e.g. semantic participant roles in lexical semantic representations of verbs linked to semantic participant roles in lexical semantics

$gallery port$
$widec$
![Image](img$qz4w)
$/widec$
$/gallery port$

$p=466$

#### The source of construction grammar

idioms
- the source of construction grammar
- linguistic expressions that are syntactically and/or semantically idiosyncratic in
various ways 
	- but: larger than words!
	- cannot simply be assigned to the lexicon without some special mechanism

idioms and the componential model
- problematic! -> to 'work', they need shared information across all levels
- => no proper place in the componential model for idioms

==*schematic idioms*==
- especially interesting
- they have some form of schematicity, but still feature a lexical component (and their own interpretation)

$p=467$

$widec$
$down
$/widec$

proposal of ==constructions==
- objects of **syntactic representation** that also contain **semantic** and even **phonological information**
	- phonological information can be special rules of phonological reduction, as in *I wanna go too*

[ Constructions <-> lexical items in the componential model ]
|constructions|lexical items|
|---|---|
|link together idiosyncratic or arbitrary phonological, syntactic and semantic information||
|at least partially schematic and complex (consisting of more than one syntactic element)|substantive and atomic -> minimal syntactic units|

$p=468$

$example$
**Resultative construction**

1. This nice man probably just wanted Mother to . . . kiss him unconscious.
(D. Shields, _Dead Tongues_, 1989)
2. I had brushed my hair very smooth. (C. Brontë, _Jane Eyre_, 1847)

- the Resultative construction has **no lexically specific element**. 
- can be described only by a syntactic structure, in this case `[NP Verb NP XP]`
- with a unique specialized semantic interpretation
$/example$

#### Extending constructions to all of grammar

----
$widec$
It is a short step from analysing the Resultative construction as a construction to analysing _all_ the syntactic rules of a language as constructions.
$/widec$
----

$rewrite$
VP -> V NP can be formulated as schematic construction [V NP]
$/rewrite$

$wide$
- $result regular syntactic rules and regular rules of semantic interpretation are _themselves_ constructions
$/wide$

$reader$
The only
difference between regular syntactic rules and their rules of semantic interpretation
and other constructions is that **the former are wholly schematic** while **the latter
retain some substantive elements**. Likewise, Goldberg (1995: 116–19) suggests that
_there is a Transitive construction just as there are more specialized schematic
syntactic constructions such as the Resultative construction_. **Reanalyzing general
syntactic rules as the broadest, most schematic constructions of a language is just
the other end of the substantive-schematic continuum for idioms/constructions.**
$/reader$

$reader$
Turning to semantic interpretation, one can also argue that **semantically idiosyncratic constructions and compositional semantic rules differ only in _degree_, not
in _kind_**. Most idioms are what Nunberg, Sag, and Wasow (1994) call **idiomatically
combining expressions**, in which the **syntactic parts of the idiom** (e.g., _spill_ and
_beans_) **can be identified with parts of the idiom’s semantic interpretation** (‘divulge’
and ‘information’, respectively). They argue that **idiomatically combining expressions are not only semantically analyzable, but also semantically compositional**.

(makes sense!)

$gallery port$
$widec$
![Image](img$tm6p)
$/widec$

$widec$
(p. 469)
$/widec$
$/gallery port$

The traditional description of idioms is that the meaning of the idiomatically
combining expression is ‘‘non-compositional.’’ But this is not the correct description. (p. 469)
$/reader$

----
$widec$
**Continuum of conventionality in semantic composition**

idiomatically combining expressions ------------------------------------> selectional restrictions
$/widec$
----

selectional restrictions
- restrictions on **possible combinations of words**
- determined **only** by the semantics of the concepts denoted by the word

$example$
$columns$
$acco$
1. Mud oozed onto the driveway.
1. ?\*The car oozed onto the driveway.
$/acco$

$acco$
1. The car started.
1. ?\*Mud started.
$/acco$
$/columns$

- $result _mud_ is a viscous substance, _car_ is a machine
- $result semantic restrictions are reflected in grammatical selectional properties
$/example$

$p=469$

$p=470$

#### Compositionality

compositionality
- the meanings of the _parts_ of the construction are combined to form the meaning of the whole construction
- semantic interpretation rules associated with a construction are unique to that construction and not derived from another more general syntactic pattern (for idioms)

$reader$
[The] analysis of idiomatically combining expressions can easily be extended to the general rules of semantic interpretation that link syntactic and semantic structures. In other words,
**all syntactic expressions, whatever their degree of schematicity, have rules of semantic interpretation associated with them**, although some substantive idioms
appear to _inherit_ their semantic interpretation rules from **more schematic syntactic
expressions** such as `[Verb Object]`. In semantics as well as syntax, the concept of
a construction can be generalized to encompass the full range of grammatical
knowledge of a speaker.

$info$
Similar arguments can be applied to morphology.
$/info$
$/reader$

#### Lexicon

lexicon
- differs only in _degree_ from constructions

$p=471$

|constructions|lexicon|
|---|---|
|complex -> made up of words and phrases|syntactically simple|

$info$
Some words are morphologically complex, of course. But
construction grammar would analyze morphologically complex words as constructions whose parts are morphologically bound. 
$/info$

$widec$
$down

**generalised constructions** display a **uniform representation of all grammatical knowledge in the speaker's mind**

$result everything from words to the most general
syntactic and semantic rules can be represented as constructions
$/widec$

## Word grammar

## Diachronic linguistics

## Lexical variation and change