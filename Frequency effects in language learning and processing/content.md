# Frequency effects in language learning and processing

$public=true$

$p=1$

## Introduction

----
$widec$
Stefan Th. Gries
$/widec$
----

$p=7$

## What can we count in language, and what counts in language acquisition, cognition and use?

---
$widec$
Nick C. Ellis
$/widec$
---

$p=1$

$reader$
**Summary**

Ellis discusses the
interrelation of frequency and cognition – in cognition in general as well
as in (second) language cognition – and, most importantly given current
discussions in usage-based approaches to language, provides a detailed
account of the factors that drive the kind of associative learning assumed
by many in the field: type and token frequency, Zipfian distributions as
well as recency, salience, perception, redundancy etc. Just as importantly,
Ellis derives a variety of conclusions or implications of these factors for
our modeling of learning and acquisition processes, which sets the stage
for the papers in this volume.
$/reader$

$p=7$

### Frequency and cognition

#### Cognition

three major experiential factors that affect cognition
- frequency
- recency
- context

$widec$
$down
$/widec$

$reader$
1. The **more times** we experience something, the **stronger** our memory for it,
and the more fluently it is accessed.
2. The **more recently** we have experienced 
something, the **stronger our memory** for it, and the more fluently it
is accessed. (Hence your more fluent reading of the prior sentence than the
one before).
3. The **more times** we experience **conjunctions of features**, the
more they become **associated** in our minds and the more these subsequently 
affect perception and categorization; so a stimulus becomes
associated to a context and we become more likely to perceive it in that
context. 
$/reader$

$p=7-8$

percept
- a complex state of consciousness in which antecedent sensation is supplemented by consequent ideas which are
closely combined to it by association

$p=8$

#### Categorisation

categorisation
- testament to human 'tallying' (Ellis 2002)

$widec$
$down
$/widec$

fuzzy natural categories
- e.g. Wittgenstein (1953) -> organised through **family resemblances**

$reader$
[S]on may be like mother, and mother like sister, but in a very different
way. And we learn about these families, like our own, from experience.
Exemplars are similar if they have **many features in common** and **few 
distinctive attributes** (features belonging to one but not the other); the more
similar are two objects on these quantitative grounds, the faster are people
at judging them to be similar (Tversky 1977).
$/reader$

prototypes
- exemplars which are most typical of a category
- similar to many members of the category, but not similar to members of other categories
- (Rosch & Mervis 1975, Rosch et al. 1976)

$reader$
Prototypes are judged **faster** and **more accurately**, even if they
themselves have never been seen before [...] Such effects make 
it very clear that although people don’t go
around consciously counting features, they nevertheless have very accurate
knowledge of the **underlying frequency distributions** and their **central
tendencies**.
$/reader$

$p=9$

### Frequency and language cognition

#### Why frequency is important

----
$widec$
Language processing is very sensitive to usage frequency  
$down  
at *all* levels of language representation!
$/widec$
----

$result (Ellis 2002)
- phonology and phonotactics
- reading
- spelling
- lexis
- morphosyntax
- formulaic language
- language comprehension
- grammaticality
- sentence production
- syntax

$reader$
Language knowledge involves **statistical knowledge**, so humans learn more easily and
process more fluently **high frequency forms** and ‘regular’ patterns which
are exemplified by many types and which have few competitors. 
$/reader$

language learning according to psycholinguists
- implicit associative learning of representations that reflect the probabilities of occurrence of form-function mappings

the rules of language
- structural regularities
- emerge from analysis of distributional characteristics of language inplut
- ~= what AI models are doing nowadays

#### Theoretical framework

usage-based linguistics
- a theoretical model
- 'we learn linguistic constructions while engaging in communication'

constructions
- form-meaning mappings
- conventionalised in the speech community
- entrenched as language knowledge in the learner's mind

$p=10$

$reader$
Goldberg’s
(2006) Construction Grammar argues that all grammatical phenomena
can be understood as learned pairings of form (from morphemes, words,
idioms, to partially lexically filled and fully general phrasal patterns) and
their associated semantic or discourse functions: ‘‘the network of constructions 
captures our grammatical knowledge _in toto_, i.e. It’s constructions
all the way down’’ 
$/reader$

### Frequency and Second Language Acquisition

$widec$
skipped
$/widec$

$p=11$

### Construction learning as associative learning from usage

$widec$
if
$/widec$

constructions
- form-function mappings
- the 'units' of language

$widec$
$down then...
$/widec$

language acquisition
- inducing **associations** between form and function from **experience** of language usage

$result how?
- distributional analysis of the language stream
- parallel analysis of contingent perceptual activity
- abstract constructions? -> learnt from the conspiracy of concrete exemplars
- statistical learning mechanisms (==Christiansen and Chater 2001==)

----
$widec$
Determinants of learning
$/widec$
----

**1.** input frequency
- type-token frequency
- Zipfian distribution
- recency

**2.** form
- salience
- perception

**3.** function
- prototypicality of meaning
- importance of form for message comprehension
- redundancy

**4.** interactions between all
- contingency of form-function mapping

#### Input frequency

##### Construction frequency

frequency of exposure
- promotes learning

$widec$
$down
$/widec$

$wide$
phonology and phonotactics, reading, spelling, lexis, morphosyntax, formulaic language, language comprehension, grammaticality, sentence production, syntax
$/wide$

$result sensitivity to input frequencies
- shows that language users actually register these frequencies
- => evidence for usage-based models of language acquisition (and processing)

$p=12$

##### Type and token frequency

|token frequency|type frequency|
|---|---|
|how often a particular form appears in the input|the number of distinct lexical items that can be substituted in a given slot in a construction\*|

$widec$
\* can be both a word-level construction for inflection or a syntactic construction
$/widec$

###### Type frequency

type
- licenses the productivity of phonological, morphological and syntactic patterns
- why? $see $down

$reader$
1. the more lexical items that are heard in a certain position in a construction, the less
likely it is that the construction is associated with a particular lexical item
and the more likely it is that a **general category** is formed over the items
that occur in that position;
1. the more items the category must cover, the
more general are its criterial features and the more likely it is to **extend** to
new items; 
1. high type frequency ensures that a construction is used
**frequently**, thus strengthening its representational schema and making it
more accessible for further use with new items
$/reader$

$info$
(so, in conclusion, it's just cognitively advantageous, and thus easy to defend this position)
$/info$

###### Token frequency

token
- promotes entrenchment / conservation of **irregular forms** and **idioms**

$info$
Irregular forms only survive because they are high frequency.
$/info$

$p=13$

##### Zipfian distribution

Zipf's law (1949)
- "in human language, the frequency of words decreases as a power function of their rank in the frequency table"
- many language events (e.g., frequencies of phoneme and letter strings, of words, of grammatical constructs, of formulaic phrases, etc.) across
scales of analysis follow this law (Ferrer i Cancho and Sole´ 2001, 2003)

learning categories from exemplars
- acquisition is optimized by the introduction of an **initial, low-variance sample** centered upon prototypical exemplars (Elio and Anderson 1981, 1984)
- allows learners to get a fix on what will account for most of the category members

$p=14$

##### Recency

recency effects / priming
- observed in phonology, conceptual representations, lexical choice and syntax (Pickering and Ferreira 2008)

$widec$
$down
$/widec$

syntactic priming
- the phenomenon of using a particular syntactic structure given
prior exposure to the same structure

$info$
This behavior has been observed when speakers hear, speak, read or write sentences (Bock 1986; Pickering 2006; Pickering and Garrod 2006).
$/info$

$p=15$

#### Form (salience and perception)

salience
- general perceived strength of stimuli

$result low salience cues
- tend to be less easily learnt

$reader$
Many grammatical meaning-form relationships, particularly those that
are notoriously difficult for second language learners like grammatical
particles and inflections such as the third person singular -s of English,
are of low salience in the language stream. For example, some forms are
more salient: ‘**_today_**’ is a stronger psychophysical form in the input than
is the **morpheme ‘-_s_’** marking 3rd person singular present tense, thus
while both provide cues to present time, **_today_ is much more likely to be
perceived**, and -_s_ can thus become overshadowed and blocked, making it
difficult for second language learners of English to acquire (Ellis 2006,
2008; Goldschneider and DeKeyser 2001).
$/reader$

#### Function

##### Prototypicality of meaning

central category members
- some members of categories are more typical of the category than others -> show the family resemblance more clearly

$widec$
$down
$/widec$

prototype
- the 'best' example of the category
- summarises the most representative attributes of category

$p=16$

$result token frequency
- very important contributor to the centrality of the prototype

##### Redundancy

redundant cues
- tend not to be acquired
- also found in the ==Rescorla-Wagner model== (1972)

$reader$
Not only are many grammatical meaning-form
relationships low in salience, but they can also be redundant in the 
understanding of the meaning of an utterance. For example, it is often 
unnecessary to interpret inflections marking grammatical meanings such as tense
because they are usually accompanied by adverbs that indicate the 
temporal reference. Second language learners’ reliance upon adverbial over
inflectional cues to tense has been extensively documented [...]
$/reader$

#### Interactions between these (contingency of form-function mapping)

contingency of mapping (Shanks 1995)
- important

$p=16-17$

$reader$
Consider how, in the learning of the category of birds,
while eyes and wings are equally frequently experienced features in the
exemplars, it is wings which are distinctive in di¤erentiating birds from
other animals. Wings are important features to learning the category of
birds because they are reliably associated with class membership, eyes are
neither. Raw frequency of occurrence is less important than the contingency 
between cue and interpretation.
$/reader$

$p=17$

#### The many aspects of frequency and their research consequences

$p=18$

$reader$
[W]hat we really want is a model of usage and its
effects upon acquisition. We can measure these factors individually. But
such counts are vague indicators of how the demands of human interaction 
affect the content and ongoing co-adaptation of discourse, how this
is perceived and interpreted, how usage episodes are assimilated into the
learner’s system, and how the system reacts accordingly. We need theoretical 
models of learning, development, and emergence that takes these
factors into account dynamically. 
$/reader$

### Language learning as estimation from sample: implications for instruction

$widec$
(skipped)
$/widec$

$p=20$

### Exploring what counts

----
$widec$
Not everything that we can count in language counts in language cognition and acquisition
$/widec$
----

$reader$
If it did, the English articles the and a alongside frequent morphological inflections would be among the first learned
English constructions, rather than the most problematic in L2A.
$/reader$

$widec$
associative learning affected by...
$/widec$

**1.** factors relating to the ==_form_==
- i.e. frequency, salience

**2.** factors relating to ==_learner attention_==
- i.e. automaticity, transfer, blocking

$wide$
- $result raw frequency counts are **too simple** (that's the idea)
$/wide$

$p=21$

### Emergentism and complexity

emergentism
- general framework
- quantitative, multivariate, multi-agent

#### Agents

agents everywhere
- "from neuron, through self, to society"
- => language emergence as a function of interactions within and between them

$reader$
[M]ore recently, work
within Emergentism, Complex Adaptive Systems (CAS), and Dynamic
Systems Theory (DST) has started to describe a number of scale-free,
domain-general processes which characterize the emergence of pattern across
the physical, natural, and social world
$/reader$

#### Complexity theory

----
$widec$
Emergentism and Complexity Theory (MacWhinney 1999; Ellis 1998;
Elman et al. 1996; Larsen-Freeman 1997; Larsen-Freeman and Cameron
2008; Ellis and Larsen-Freeman 2009, 2006)
$/widec$
----

idea
- how do complex patterns emerge from the interactions of many agents?

$p=22$

$reader$
<span style="color: red;">‘‘Emergentists believe that **simple learning mechanisms** [..] **suffice** to drive the emergence of complex language representations.’’ (Ellis 1998, p. 657)</span>
$/reader$

#### Complex adaptive system

----
$widec$
Language considered as a CAS of dynamic usage and its experience
involves the following key features
$/widec$
----

$wide$
- The system consists of **multiple agents** (the speakers in the speech community) interacting with one another.
- The system is **adaptive**, that is, speakers’ behavior is based on their
**past interactions**, and **current and past interactions** together **feed forward**
into future behavior.
- A speaker’s **behavior** is the **consequence of competing factors** ranging
from perceptual mechanics to social motivations.
$/wide$

$widec$
$down
$/widec$

advantage of CAS
- provides a **unified account** of seemingly unrelated linguistic phenomena (Holland 1998, 1995; Beckner et al. 2009)

$wide$
- variation at all levels of linguistic organization
- the probabilistic nature of linguistic behavior
- continuous change within agents and across speech communities
- the emergence of grammatical regularities from the interaction of agents in
language use
- stage-like transitions due to underlying non-linear processes
$/wide$

$reader$
<span style="color: red;">Much of CAS research investigates these interactions through the
use of **computer simulations** (==Ellis and Larsen-Freeman 2009==).</span>
$/reader$

### Zipf, corpora, and complex adaptive systems

$p=23$

==Principle of Least Effort== (Zipf 1949)
- reasoning behind Zipf's law
- balancing...
	1. speaker effort (optimized by having fewer words to be learned and accessed in speech production) 
	2. ambiguity of speech comprehension (minimized by having many words, one for each different meaning)

$reader$
It has become a hallmark of Complex Systems theory
where so-called fat-tailed distributions characterize phenomena at the edge
of chaos, at a self-organized criticality phase-transition point midway
between stable and chaotic domains.
$/reader$

$p=24$

$reader$
Language usage,
social roles, language learning, and conscious experience are all socially
situated, negotiated, sca¤olded, and guided. They emerge in the dynamic
play of social intercourse. All these factors conspire dynamically in the
acquisition and use of any linguistic construction. **The future lies in trying
to understand the component dynamic interactions at _all_ levels**, and the
consequent emergence of the complex adaptive system of language itself.
$/reader$

$p=35$

## Are effects of word frequency effects of context of use?

----
$widec$
William D. Raymond and Esther L. Brown
$/widec$
----

$p=2$

$reader$
**Summary**

Raymond & Brown explore a range of frequency-related factors and
their impact on initial fricative reduction in Spanish. They begin by 
pointing out that results of previous studies have been inconclusive, in part
because many different studies have included only partially overlapping
predictors and controls; in addition, the exact causal nature of frequency
effects has also proven elusive. They then study data on [s]-initial Spanish
words from the free conversations from the New Mexico-Colorado Spanish
Survey, a database of interviews and free conversations initiated in 1991.
A large number of different frequency-related variables is coded for each
instance of an _s_-word, including word frequency, bigram frequency, 
transitional probability (in both directions), and others, and these are entered into
a binary logistic regression to try to predict fricative reduction.

The results show that s-reduction is influenced by many predictors, too
many to discuss here in detail. However, one very interesting conclusion is
that, once a variety of contextual frequency measures is taken into consideration, 
then non-contextual measures did not contribute much to
the regression model anymore, which is interesting since it forces us to
re-evaluate our stance on frequency, from a pure repetition-based view
to a more contextually-informed one, which in itself would constitute a
huge conceptual development (cf. also below).
$/reader$

$p=35$

### Introduction

#### The link between word frequency and reduction

word frequency
- the relative **cumulative experience** that speakers have with words

$p=36$

$widec$
$down
$/widec$

word frequency and *reduction*
- widely studied -> word frequency impacts both **diachronic change** and **synchronic production variation**

$reader$
Investigations of the processes of _**sound
change**_ in language going back over a century 
have noted that more **frequent words are shorter** and 
**change more quickly** than less frequent words
(Schuchart 1885; Zipf 1929).
$/reader$

$reader$
In studies of _**synchronic pronunciation variation**_, 
evidence has been offered that **higher word frequency** is associated
with **more word reduction** in speech production, as measured by both
categorical measures of segment reduction or deletion (Bybee 2001, 2002;
Krug 1998; Jurafsky et al. 2001; Raymond, Dautricourt, and Hume 2006)
and also continuous measures of reduction, including durational shortening 
(Gahl 2008; Jurafsky et al. 2001; Pluymaekers, Ernestus, and Baayen
2005) and some acoustic parameters (Ernestus et al. 2006; Myers and Li
2007).
$/reader$

$widec$
$down
$/widec$

$widec$
how does frequency of word use contribute to the reductive process?
$/widec$

#### Footnotes on the relation between frequency and reduction

other factors
- lexical structure and class
- extra-lexical phonological context
- prosodic environment
- speech rate
- sociolinguistic factors
- probabilistic variables
- but: usually frequency is predictive at *some* level

$reader$
[H]owever,
frequency effects are not ubiquitous.

- For example, Pluymaekers et al.
(2005) found that word frequency affected reduction of affix form and
duration for most but not all of the morphologically complex Dutch
words they studied.
- Similarly, some of the high-frequency function words
examined by Jurafsky et al. (2001) had low rates of reduction, despite their
high frequency and a control for phonological context. 
- Finally, Cohn et al.
(2005) found no effect of word frequency on durational shortening of homophones, although Gahl (2008) did.
$/reader$

$widec$
$down how is this possible?
$/widec$

$acco$
**1.** methodological differences
- sample size  (see Gahl 2008)
- the set of factors considered in the study
$/acco$

$widec$
$down
$/widec$

$p=37$

$acco$
**2.** likelihood
- the likelihood that a word occurs in discourse contexts in a phonological environment that _**promotes**_ reduction (Bybee 2001, 2002; Timberlake 1978)

$reader$
- For example, the rate of word-final t/d deletion
in English is lower for words that are more likely to occur in the context
of a following vowel in speech (Guy 1991; Bybee 2002).
- Similarly, reduction rates of word-initial [s] in Spanish are higher for words that are more
likely to occur in the context of a preceding non-high vowel in speech
(Brown 2004, 2006). 
$/reader$
$/acco$

#### Motivation for reduction

automation
- reduction is the result of the **automation of production processes** (Bybee 2001, 2002)
- claimed to result in more **casual, reduced forms**
- ultimately: registered as change in lexical representation

$widec$
$down ??
$/widec$

*nature* of reduction
- basic frequency of use should occur **uniformly** across the word
- however: it occurs on certain segments or syllables

$widec$
$down why?
$/widec$

influence of lexical structure and discourse environments
- leads to differential articulatory effects, automation processes (and ultimately, reduction)

$wide$
- => in a study, you have to control for all of these factors
$/wide$

$p=38$

$reader$
In the current study whether word frequency plays an independent role
in on-line _s-_ reduction is addressed by **controlling both word frequency
and frequency of occurrence of a word in phonological environments known
to promote articulatory reduction of [s-]**. The effects of **other probabilistic
measures** are also assessed, to determine whether they contribute to s- reduction. 
Both intra- and extra-lexical phonological contexts are controlled, and
comparison of their effects is used to determine to what extent reduction can
be attributed to lexical representations or on-line articulatory processes.
$/reader$

### Data and methods

$p=41$

$reader$
As an illustration of the measures in Table 2, consider the excerpt from
the corpus transcription in (1).

1. . . . _a mi sobrino, porque yo_ . . .  
. . . to my nephew, because I . . .

The s- word _sobrino_ in the token in (1)
occurs 11 times in the NMCOSS corpus, giving it a frequency per million
of 146 and a log frequency of 2.17. The preceding word bigram in this
token is _mi sobrino_, which has a frequency in the corpus statistics of 6,
and the frequency of the word preceding the s- word, _mi_, is 485, so that
the predictability of _sobrino_ from _mi_ is 6/485 = .0124. The s- of _sobrino_ in
this token is followed (word-internally) by the non-high vowel /o/, which
is a context hypothesized to favor s- reduction. However, 
the vowel preceding s- is the high vowel /i/ in _mi_, which is hypothesized not to favor
reduction. Overall in the corpus the word _sobrino_ occurs after a non-high
vowel (/o/, /a/, or /e/) only once, giving _sobrino_ a FFC of 1/11 = .091.
The frequency with which /i/ precedes /s/ at a word boundary in the
corpus is 407, and the log of this frequency per million phones is 2.61.
$/reader$

$p=44$

### Results

$p=44-45$

$wide$
- main effect of preceding and following phonological contexts of s-
	- non-high vowels (before) predict higher reduction rates (2.41 times more likely)
	- non-high vowels (after) predict higher reduction rates (3.03 times more likely)
- no lexical stress on the initial syllable of an s-word predicts higher reduction (1.59 times more likely)
- predictability hardly leads to higher reduction (1.01 times -- so 1% -- more likely)
$/wide$

$p=45$

$gallery$
![Image](img$4o7j)
$/gallery$

$p=47$

### Discussion

reduction effects
- both **==extra-==** and **==intra-lexical== factors**
- cumulative experience (frequency) factor and context

$p=48$

$reader$
- <span style="color: red;">The effect of the predictability of the s- word from the preceding word was small.</span>
- However, the effect of FFC [(frequency in a favourable context -- how often does the 
word occur before a vowel conducive to reduction?)] was robust and confirms earlier findings that **FFC
encourages reduction in studies that did not control other probabilistic
factors** (Brown 2004, 2006). The effect of FFC indicates that **the _cumulative experience_ 
of words in reducing phonological contexts of non-high
preceding vowels results in a greater likelihood of reduction than context
of use alone can explain**. The effect suggests that reduction of s- reflects
changes in the lexical representations of words **through cumulative experience** 
with these words in reductive production contexts. 
$/reader$

$p=49$

$reader$
The <span style="color: red;">failure to find any robust effects of the non-contextual word and
phone unit probabilities</span> after controlling the contextual variables suggests
that **<span style="color: red;">speakers are sensitive to how often a word occurs in environments that
encourage reduction</span>**, but not measurably to non-contextual probabilistic
measures of use. Consequently, an s- word’s frequency did not predict /s-/
reduction.
$/reader$

$reader$
How can <span style="color: red;">the failure to find a significant effect of word frequency</span> on 
s-reduction in datasets analyzed be reconciled with other studies, in which
word frequency effects on a range of reductive processes have been reported?

- As noted, in most of these studies **the likelihood of a word occurring in a
reducing environment was not controlled**. With respect to phonological
context, the environments promoting reduction are generally identifiable,
and tests of their importance could be readily made. 
- However, other variables not examined in this study may also promote reduction differentially
across the word frequency range.
	- For example, higher rates of speech are
associated with reduction, and words may differ in their likelihood of
being produced at high speech rates.
	- In addition to a direct effect of speech
rate on reduction, **higher frequency words may, in particular, be more
likely to be produced in contexts with higher speech rates than lower
frequency words**. Because faster speech rates may encourage reduction,
high frequency words would thus have a higher probability of occurring
in this reducing environment.
$/reader$

$p=109$

## Frequency, conservative gender systems and the language-learning child: Changing systems of pronominal reference in Dutch

----
$widec$
Gunther De Vogelaer
$/widec$
----

$p=3$

$reader$
**Summary**

De Vogelaer studies the gender systems of Dutch dialects. More specifically, 
he starts out from the fact that Standard Dutch exhibits a gender
mismatch of the binary article system and the ternary pronominal system
and explores to what degree this historical change is affected by frequency
effects. Results from a questionnaire study, in which subjects were put in
a position to decide on the gender of nouns, indicate high- and lowfrequency items 
behave differently: the former are affected in particular
by standardization whereas the latter are influenced more by resemanticization.
However, the study also cautions us that different types of data
can yield very different results with regard to the effect of frequency. De
Vogelaer compares frequency data from the 9-million-word Spoken Dutch
Corpus to age-of-acquisition data from a target vocabulary list. Correlation 
coefficients indicate that the process of standardization is more correlated with 
the adult spoken corpus frequencies whereas resemanticization
is more correlated with the age-of-acquisition data. As De Vogelaer puts
it, ‘‘frequency effects are typically poly-interpretable,’’ and he rightly advises
readers to regularly explore different frequency measures and register-specific frequencies.
$/reader$

$p=109$