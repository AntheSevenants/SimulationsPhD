# Language and Complex Systems

$public=true$

$reader$
**Abstract**

An understanding of language as a complex system helps us to think differently
about linguistics, and helps us to address the impact of linguistic interaction.
This book demonstrates how the science of complex systems changes every
area of linguistics: how to make a grammar, how to think about the history of
language, how language works in the brain, and how it works in social settings.
Kretzschmar argues that to construct the best grammars of languages, it is
necessary to understand the complex system of speech. Each chapter makes
specific recommendations for how linguists should manage empirical data in
order to form better generalizations about a language and its varieties. The
book will be welcomed by students and scholars working in linguistics and
English language, especially the study of language variation and the historical
development of English.
$/reader$

$p=1$

## Introduction

the 'cause' of language
- previously: Universal Grammar seen as a cause

$widec$
$contrast
$/widec$

recent views
- some effects arise **without particular causes**, as the result of
**random interactions of large numbers of elements in complex systems**
- => effects *emerge*

$p=2$

"order for free" (Kaufman 1995: 83)
- we achieve regularity in behaviour without any simple cause
- regularities do not occur at the cost of particular causes

$widec$
$down
$/widec$

speech / language in use
- order in language emerges from the linguistic interactions of speakers

$p=3$

$reader$
The most
basic assumption of generative and structural linguistics, that we speakers all
share the system of a language, share the rules for a language, is simply **wrong**.
We all participate in speech, but the language is a little different, both in its
available features and in the frequency with which we use those features, for
each one of us individually and for each of us as a participant in every group to
which we belong.
$/reader$

generalisations
- made *after* the fact to help us organise our perceptions

$p=5$

## Language and complex systems

### History of language and complex systems

$deflist$
**Definition of a complex system (<span style="color: red;">Mitchell 2009</span>: 13)**

a complex system is “a system in which **large
networks of components** with **no central control** and **simple rules of operation**
**give rise to complex collective behavior**, sophisticated information processing,
and adaptation via learning or evolution.”
$/deflist$

"complex"?
- *not* 'complicated'
- rather: 'numerous'

$reader$
**Complexity science at Santa Fe Institute (SFI)**

doing complexity science required a commitment to observation, experience, 
and experiment that is in balance with the transdisciplinary, out-of-the-box curiosity that gave rise
to the original question. It’s **not** that outcomes in complex adaptive systems are **repeatable** as they 
are in many scientific disciplines; complex systems are by definition **unpredictable**, and often 
downright squirrelly. But finding the **patterns embedded in complex
systems** requires a distinct brand of scientific rigor and methodological approaches that
in many cases haven’t yet been invented.
$/reader$

$p=6$

'adversary' of complexity science
- cause-and-effect reductionism

way of working
- still: empirical observation and rigorous methods
- but: we do not expect that simple causes can be found for the effects we observe
	- behaviour is embedded in a large network without a central control

$reader$
While complexity science was taking off at SFI, it did receive some early 
allusive discussion in linguistics: Lindblom, MacNeilage, and Studdert-Kennedy
published a 1984 paper on self-organizing processes in phonology; Paul Hopper 
presented his seminal paper called “Emergent Grammar” in Berkeley in
1987 (see Chapters 3 and 4); Ronald Langacker published a chapter titled “A
Usage-Based Model” for cognitive linguistics in 1988. Gradually more papers
attempting to use complex systems in linguistics appeared in the 1990s, such as
Van Geert (1991). In 1996 Edgar Schneider presented a paper whose title was
a question, “Chaos Theory as a Model for Dialect Variability and Change?”
(published 1997). At that time, it had already been over twenty years since the
original paper on climate by Edward Lorenz that asked the question, “Does the
Flap of a Butterfly’s Wings in Brazil Set off a Tornado in Texas?” (1972), and
over ten years since the founding of the SFI, where chaos theory was studied
as part of the emerging field of complexity science. But it was very early for
a student of language to consider the subject as a serious model for speech.
In the same year, J. K. Chambers commented in a book review that “We will
need a coterie of sociolinguists expert in chaos theory before we can make
a start [at applications to our field]” (1996: 163). Chambers noted that the
biggest problem for language applications then was that chaos theory seemed
to require a long series of observations over time, a rare commodity for those
who systematically record language in use. 
$/reader$

### Examples of complex systems

ants
- not centrally controlled, yet seem highly organised
- more in Mitchell 2009: 176-187

$p=8-9$

features of an ant colony
- random behaviour: choice between foraging, nest building and defence is not deterministic!
- necessary: if focussed on one sort of behaviour, might be vulnerable
- but: communication *among* ants might influence behaviour needed at that moment

$p=9$

#### Game of Life

$p=10$

$gallery$
RIP John Conway :'(

![Image](img$zy5r)
$/gallery$

Game of Life
- simple rules determine whether a cell is dead or alive

initial state
- very important
- depending on the initial constellation, behaviour might die out *or* be perpetual
- ~= sensitive dependence on initial conditions

==cellular automaton==
- a complex system based on simple cells

$p=11$

### Principles of complex systems

#### Properties of complex systems

----
$widec$
Basic principles of complex systems
$/widec$
----

$p=19$

**1.** continuing **dynamic activity** in the system
- so: no static structure

**2.** random interaction of **large numbers of components**
- components don't stand still in an hierarchical arrangement of types

**3.** exchange of information with **feedback**
- probabilistic feedback keeps the system from becoming stuck in rule-bound relations

**4.** **reinforcement** of behaviors
- reinforcement of behaviours from feedback creates non-linear distributions of units, as opposed to random or statistically normal distribution
	- at _every_ level of scale instead of at just one level characterised by homogeneous unity

$wide$
**5.** emergence of **stable patterns without central control**
$/wide$

$p=11$

$reader$
**More chaos echoes**

The mathematician
Benoit Mandelbrot claimed that “many patterns of Nature are so irregular and
fragmented, that, compared to [standard geometry] Nature exhibits not simply
a higher degree but an altogether different level of complexity” (1982: 1). His
treatment of natural forms like the geometry of coastlines presented problems
that could not be solved with traditional methods but required a new nonlinear
mathematics, what he called “**fractals**.” Fractals are familiar to many of us
through repeating graphic designs like the “Koch islands” in Figure 1.3. The
basic properties of fractals – including scaling properties, as illustrated here –
characterize many objects of study in the physical, natural, and social sciences,
not just graphic designs

$gallery port$
$widec$
![Image](img$527j)
$/widec$

$widec$
Koch Island (p. 12)
$/widec$
$/gallery port$
$/reader$

$p=12$

#### Types of systems

|equilibrium system|non-equilibrium system|
|---|---|
|closed|open|
|do not exchange matter or energy outside the system|exchange energy of matter outside the system|
|components are balanced|components are continually negociating|

$widec$
**Equilibrium systems**
$/widec$

$columns$
$example$
**Low-energy equilibrium system**

Kauffman offers the example of dropping
a ball down the side of a bowl: the ball will roll up and down the sides but will eventually come to rest at the bottom of the bowl, at low-energy equilibrium.
$/example$

$example$
**High-energy equilibrium system**

In
the case of an energetic equilibrium system, again in Kauffman’s example, if we
put a quantity of gas molecules into a tank, the molecules do not stay ordered
in a group at the point of entry; they keep moving around in the tank, and
according to the ergodic theory they move randomly through all of the statistically
possible states of arrangement.
$/example$
$/columns$

$p=12-13$

$columns$
$example$
**Non-equilibrum system**

Kauffman sets the counter example of the small whirlpool that forms near drains: this ordered structure will
be maintained as long as the drain remains open and water continues to flow The order in such a non-equilibrium system is sustained by persistent dissipation of matter and energy, and thus the whirlpool can be called
a “dissipative structure” of the kind described by Prigogine. No stirring is
required to start the whirlpool, no single and simple cause. The water is subject
to natural laws like gravity that makes the water drain, but no collection of laws
completely explains the whirlpool because randomness in the molecules and
conditions is involved in the emergence of every particular whirlpool. 
$/example$
$/columns$

$p=15$

[scale-free network](https://www.futurelearn.com/info/courses/social-media/0/steps/16046)
- a network "in which the distribution of links to nodes follows a power law"
- the vast majority of nodes have very few connections, while a few important nodes (we call them Hubs) have a huge number of connections

$p=17$

chaotic systems
- **deterministic** -> small changes in initial conditions lead to significantly different future behaviour
	- complex systems _do_ require sufficient conditions for their operations, such as enough
live cells in the Game of Life to allow the rules to operate in a complex way, but
they are **not deterministic**
- also: intermittency / cyclic behaviour

$example$
We still get a whirlpool or bubble
patterns at different water levels, or if someone should wade in the water and
disturb the flow.
$/example$

$p=17-19$

$reader$
Descriptions of self-organization typically use data collected in time series,
and apply complex mathematical operations to generate **“attractors,”** as shown
by Guastello and Liebovitch for psychology (Figure 1.9). As for the application
of successive values to make Mandelbrot’s San Marco Dragon with a formula,
successive measurements of real phenomena over time may create patterns
when graphed that tend towards a fixed point (A), or create an oscillation or
orbital shape (C, E), or other patterns whose regularity may be more difficult
to see (chaotic, or “strange” attractors). Each successive moment in time corresponds to a “state” of the phenomenon being observed, whether it is traffic
in a city or economic activity in a country or evolutionary development in a
biological system.

$gallery port$
$widec$
![Image](img$cgij)
$/widec$
$/gallery port$
$/reader$

$p=19$

#### Chaotic systems <-> complex systems

|complex systems|chaotic systems|
|---|---|
|settle into a very small number of states|occupy a very large number of states|
|undisturbed by small changes||

attractor
- "another term for
**regularity** or **ordered behavior** achieved by the elements being observed"

### Language as a complex system

#### The multi-dimensionality of language

time series in language studies
- difficult!
	1. gathering data is **expensive**
	2. our data points are **rich**

$p=20$

$reader$
We do look back in time in historical linguistics to observe change, but
**we do not have enough information about how the members of a population
were actually speaking at any given time to make any more than speculative
judgments** about the state of the language in the remote past.
$/reader$

$reader$
The situation is
little better for the recent past, <span style="color: red;">when we may have more information from
writing or even from recorded speech, but **still no fair way to estimate how _all_
of the members of a population were actually speaking**</span> (see Chapter 7).~4~ This
means that **we need to look for the _effects_** of complex systems in speech in the
surveys and other collections of data that we can actually carry out.

~4~ <span style="color: red;">The problem of **rich data** also introduces **greater dimensionality** for the description of systems.</span>
Stephen Wolfram (2002) required over 1,000 pages to prepare a comprehensive description of
the patterns created by the successive states of a one-dimensional cellular automaton (a set
of eight boxes in a row, which can be either black or white), according to the application of
different rules for how the on/off pattern would change between states. Kauffman’s light bulbs
were arranged in a two-dimensional grid. Speakers as agents interact with each other in many
different ways, and **speakers can choose between many possibilities** for _any_ linguistic feature
we wish to observe.

$widec$
(my emphasis, also for the italics)
$/widec$
$/reader$

$wide$
- $result at any moment, language is **highly multi-dimensional**, but also **stable**
$/wide$

$widec$
$contrast
$/widec$

'chaotic' view of language
- long state cycles (always changing, unstable yet cyclic)

#### Language as a complex system proper

complex systems
- *can* be used to describe language varieties

$p=21$

**1.** continuing **dynamic activity** in the system
- new conversations and writings occur continuously
- => language needs to remain **in use** in order to stay alive

$p=22$

**2.** random interaction of **large numbers of components**
- self-organisation in the form of geographical, social and textual clustering of speech sounds and words
- associated in different ways with particular localities, groups or text types

**3.** exchange of information with **feedback**
- probabilistic feedback keeps the system from becoming stuck in rule-bound relations

**4.** **reinforcement** of behaviors

$p=24$

#### Zipf's Law

==Zipf's Law==
- a frequency ranking of words in texts
- **rank** is roughly **inversely related** to **frequency**

$widec$
$down
$/widec$

|quantity|frequency|
|---|---|
|"few"|very frequent words|
|"some"|moderately frequent words|
|"most"|low frequency words|

$p=28$

$gallery$
|==linear== scales on both axes|==logarithmic== scales on both axes|
|---|---|
|![Image](img$hqpt)|![Image](img$wfvo)|

$widec$
also called an ==**A-curve**==
$/widec$
$/gallery$

$p=24$

place of occurrence
- phonological variants of a single word
- lexical variants of a concept
- also appears in *subsamples*

$p=31$

$reader$
We now have an answer for Edgar Schneider’s question about chaos theory
and speech. 
No, **chaos theory is not a model for dialect variability and change**.
But speech does constitute a complex system, “at the edge of chaos.” 
$/reader$

$p=32$

#### Using the A-curve for generalisation

----
$widec$
We can use the A curve to **define the relationship between ==what
people actually say or write== and the ==generalisations== that we want to make** from
that behaviour
$/widec$
----

$widec$
$down
$/widec$

most common variants on the A-curve
- perceived as **"normal"** or **"expected"**
- => for any group (or for *no* group), we can deduce a 'linguistic system' (p. 33)

$p=33$

$widec$
$down
$/widec$

==observational artifact==
- an artifact (i.e. linguistic system) built in our *perception*
- linguistics systems do not "exist" in reality per se, but rather stem from our interpretation of reality
- => so: we can create many subcategorisations of language, but by definition these are subjective, unstable and conventional

$p=32$

long tail variants on the A-curve
- perceived as **"different"**

$result distribution itself
- gives users of speech **consistent, high-quality input** for perceptions

$reader$
So, for example, a diphthongal pronunciation of _fog_ is what we expect from
women, but not what we expect from the LAMSAS speakers overall. We can
expect ‘weeks without rain’ to be called a _dry spell_ as a normal word, but
accept that many other words are possible, and understandable, as different
variants. We can perceive the top-ranked variants of any linguistic feature for
groups at any level of scale, and the fact that different variants for a given
feature will be ranked more highly in different groups helps us to distinguish
the language behavior of the group.
$/reader$

$result 'scale-free' for language
- just as fractals are scale-free geometrical figures in mathematics, the A-curve power law is **scale independent**

$p=33$

#### Social groups, personal choice and feedback

choice of form
- speakers do not always choose the most popular form (else, there wouldn't be an A-curve)
- rather, they can *choose* whichever form fits the **situation** and the **group**

$widec$
$down
$/widec$

$p=33$

feedback and reinforcement
- different situations call for different forms
- people belong to different groups, and can position themselves for different variants

$p=34$

#### Consequences of the A-curve for linguistic theory

linguistic "system"
- does not exist -> any variety we name actually **exists as an
observational artifact** that comes from our perceptions of the available variants

$result frequency effects
- create a **complex system** which displays itself as an A-curve

$p=34-35$

$reader$
Linguistic systems as low-energy equilibrium systems are always 
**observational artifacts of our perception**, in effect
**transformations of speech data** from its natural existence as part of a complex
system. 
$/reader$

$reader$
**Analysing language in the traditional way?**

When we propose the existence of such hierarchical linguistic 
systems based ([e.g. tree-based grammar]) upon our perception of speech around us, as
we certainly want to do and are justified to do by the distributional patterns of
speech as a complex system, we need to be guided by the nonlinear distributional 
pattern of the evidence of language in use because **no system that we
describe is actually instantiated in the spoken interactions themselves**.

$widec$
(own interpolation)
$/widec$
$/reader$

$p=36$

## Linguistics, science, the humanities, and complex systems

$p=56$

## Usage-based linguistics and complex systems

$p=81$

## Grammar and complex systems

$p=105$

## Complex systems and the history of the English language

$p=131$

## Neural networks and complex systems

$p=155$

## Sociolinguistics, communities, and complex systems

$p=201$

## Postmodernism and complex systems