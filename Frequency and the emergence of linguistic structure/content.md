# Frequency and the emergence of linguistic structure

$public=true$

$p=1$

## Introduction to frequency and the emergence of linguistic structure

----
$widec$
Joan Bybee and Paul Hopper
$/widec$
----

### Introduction

#### From independent structure to usage-based structure

$reader$
In contrast, outside linguistics it is widely held that **cognitive representations are
highly affected by experience**. In humans and non-humans detailed tracking of probabilities leads to behavior that promotes survival (Kelly and Martin 1994).
$/reader$

$widec$
$down
$/widec$

$wide$
- **irregular morphological formations with high frequency** are less **likely to regularize**
- **regular patterns** have a **wider range of applicability**
- **high frequency phrases** undergo **special reduction**
$/wide$

$result Zipf
- catalogued and described these effects
- today: known for 'Zipf's law'

$reader$
Zipf coined the term ==**“dynamic philology’’**== for the quantitative study of language change and its relevance for linguistic structure.
$/reader$

$p=2$

1980s hypothesis
-  grammar comes about through the **repeated adaptation of forms to live
discourse** (Hopper 1979; Givón 1979; Givón (ed.) 1983; Hopper and Thompson 1980, 1984; Du Bois 1985)
- also: how can experience with language (**_reflected_** in frequency) affect cognitive representations and categorisation?

$reader$
Time and again the operation
of linguistic rules has been found to be **limited by lexical constraints**, sometimes to
the point where a construction is valid only for one or two specific words.
$/reader$

==_emergence_==  
(Hopper 1987, 1998, 1988, 1993)
- ongoing process of _structuration_ (Giddens 1984)
	-  “the conditions which govern the **continuity and dissolution of structures** or types of structures’’ (Giddens 1977: 120)
- emergent structures are **unstable** and are **manifested stochastically**
- => the fixing of linguistic groups of all kinds as recognizably structural units is an **ongoing process**

$p=2-3$

$reader$
“Grammar’’ itself and associated theoretical postulates like
“syntax’’ and “phonology’’ have **no autonomous existence beyond local storage and real-time processing** (Hopper 1987; Bybee, this volume). 
$/reader$

$p=3$

#### Contents of the volume

----
$widec$
Two major principles
$/widec$
----

1. The distribution and frequency of the units of language are governed by the content of people’s interactions, which consist of a preponderance of subjective,
evaluative statements, dominated by the use of pronouns, copulas and intransitive clauses.
2. The frequency with which certain items and strings of items are used has a profound influence on the way language is broken up into chunks in memory storage, the way such chunks are related to other stored material and the ease with
which they are accessed.

$p=4$

### Patterns of use in natural discourse

#### Use of natural discourse data

mismatch
- there is a very **serious mismatch** between the **results of quantitative studies** and **grammatical accounts**

$p=5$

$reader$
[Hopper and Thompson] note that lexical frames for verbs that
specify their possible argument structures in advance of usage are often violated in
practice, and that the more frequent a verb type, the less predictable the number of
arguments; a rare verb like to elapse is limited to a single argument, whereas a common verb like to get appears in discourse with one, two, or three of the traditional
arguments depending on the speaker’s need. Scheibman, arguing for the centrality
of subjective expression in conversational English, points out that this role of subjectivity is in opposition to the privileging of referential language in standard linguistic analysis.
$/reader$

#### Subjectivity

----
$widec$
How to work with discourse in frequency studies?
$/widec$
----

|contextual meaning is irrelevant|contextual meaning is very important|
|---|---|
|morphological and phonological questions|other questions|

$p=7$

$reader$
In another paper influenced by Bybee’s “Usage-based Phonology,’’ [which one???] Bush studies
the palatalization of segments across word boundaries in, for example, “would you’’
\> [wudju] as opposed to the absence of such palatalization in sequences such as
“good you’’ (which had been noted by earlier researchers). Bush invokes **transitional probability**, 
==**the degree of likelihood that one word will be followed by a
specific collocate**==. He concludes that the **discourse “chunking’’ of lexical words
creates units that may behave in every respect like unitary words, permitting the
application of processes that are otherwise word-internal (see Bybee 2000a)**. His
study indicates that frequency of cooccurrence significantly drives assimilation
whether words are function or content words. Palatalization in conversation is not
restricted to the pronoun you as suggested by some studies, nor is it possible to
predict its occurrence with reference to constituent structure. Pairs of words that are
frequently used together, whatever their apparent constituency and status as lexical
or grammatical (don’t you, told you, that you, last year), are more likely to show
effects of coarticulation than words that are used together less often.
$/reader$

$p=8$

### Units of usage

units of storage?
- *are* the units of usage!
- as **people do not speak in isolated morphemes or
words**, [...] the units of memory and processing contain **multiple morphemes** and even **multiple words** (see Wray and Perkins 2000)

categorisation of units
- network based on the user’s experience (Bybee 1998)

$p=9$

$widec$
$down
$/widec$

network ontology
- organized into **exemplars** on the basis of high **similarity** of phonetic shape and function or meaning
- such exemplars are **tagged for their contextual associations**
	- both linguistic and extra- linguistic

$result evidence
- both direct and indirect frequency effects can be demonstrated for these units

'strength'
- tokens of experience strengthen stored exemplars (Bybee 1985; Pierrehumbert, this volume)

$p=10$

### Frequency effects and cognitive mechanisms in emergent grammar

$reader$
The notion of emergent structure has become important in various branches of the
sciences in the last two decades. <span style="color: red;">The basic idea is that what may appear to be a coherent structure created according to some underlying design may in fact be the result
of multiple applications or interactions of simple mechanisms that operate according
to local principles and create the seemingly well-planned structure as a consequence</span>.
$/reader$

#### Phonological reduction in high frequency words and strings

reduction effect  
<span style="color: red;">(Schuchardt 1885)</span>
- words of higher frequency tend to undergo sound change at a faster rate than words
of lower frequency

$result graduality of sound change
- both **phonetically** and **lexically**
- specific phonetic features are associated with lexical items

$p=11$

advantage of the exemplar model
- allows distinct representation of forms (<-> non-exemplar models)
- you *need* an exemplar-based storage model of cognition to account for these types of changes

$reader$
The origins of reduction are in the **automatization of neuro-motor sequences
which comes about with repetition**. [<span style="color: red;">this is contested</span>]
$/reader$

why frequent words more often?
- they are **exposed** to [...] on-line processes [(automatisation)] **more** than infrequent words

discourse factors
- the speaker seems to be able to gauge how much phonetic information the hearer
needs in order to access the correct word ($see $down)

$reader$
Where the word is **primed** by the other words in the
context, it is also **easier to access**. The persistent use of this strategy by speakers
leads to the development of a listener strategy by which reduced words are judged
to be repetitions and thus part of the background in the discourse (Fenk-Oczlon, this
volume). Thus with the reduction the speaker signals that the reduced word is just
the same old word as used before, not a new one.
$/reader$

$p=12$

$reader$
The paper by Jurafsky et al. (this volume) takes into account a number of factors
under the Probabilistic Reduction Hypothesis, which includes not just the 
**predictability of a word** within a particular discourse, but also its **cumulative token
frequency** and the **probability of a word given neighboring words**. 

Jurafsky et al.
provide useful formulae for calculating the predictability of a word given 
the previous and following word. They study the top ten most frequent words of English,
which are all function words (_a, the, in, of, to, and, that I, it, you_). <span style="color: red;">**These words both
show more vowel reduction and shorter duration as they are more predictable from
the preceding and following word**</span>. In contrast, content words ending in /t/ or /d/
were studied for the deletion of their final consonant and here they find that <span style="color: red;">**only the
frequency of the word containing the /t/ or /d/ predicts the rate of deletion**</span>.
$/reader$

$p=13$

$widec$
$down
$/widec$

$widec$
nature of mental representation
$/widec$

#### Functional change due to high frequency

grammaticisation
- functional and semantic change due to high frequency
- the mechanism by which structure emerges from language use

$p=14$

#### Frequency and the formation of constructions

constituent structure
- determined by frequency of co-occurrence (Bybee and Scheibman 1999)
- the more often two elements occur in sequence the tighter will be their constituent structure

$example$
Clear examples are cases in which two
words have fused because of their frequent co-occurrence and now **behave essentially as single words**:

- _want to_ > _wanna_
- _going to_ > _gonna_
- _I am_ > _I’m_
- _can not_ > _can’t_
- _do not_ > _don’t_
- _I don’t know_ > _I dunno_
- _would have_ > _would’ve_

(Boyland 1996; Bybee and Scheibman 1999; Krug 1998, this volume).
$/example$

$result constituent boundaries
- lost as frequency rises

$p=16$

#### Frequency and accessibility

speed of lexical access and frequency
- strongly linked!
- so: frequency of use may make access of larger units easier as well

$reader$
Strings such as _you
and I_, _come on_, _fall over_, and common sequences with liaison in French, such as
_mes amis_ ‘my friends’, _c’est un_ ‘it’s a’, and _l’un avec l’autre_ ‘with one another’
may be more efficiently accessed as units than composed morpheme by morpheme.
$/reader$

$p=17$

#### Retention of conservative properties in high frequency units

[ Two types of change for high frequency units ]
|reductive processes|analogical change|
|---|---|
|due to language **use**|due to **analogy**|
|highly eligible|highly conservative|

$widec$
$down

different types, different susceptibility
$/widec$

$info$
For linguistic theory the major consequence of the finding that high frequency
units are resistant to reformation on the basis of productive patterns is 
that **the resistant units must have storage in memory** in order to resist change and in order to
be affected by frequency of use.
$/info$

$p=18$

#### Stochastic grammar

stochastic grammar
- 'variablity' of grammatical structure

$p=19$

$widec$
$down
$/widec$

grammar
- not fixed! -> intrinsically variable

### Conclusion

$widec$
skipped
$/widec$

$p=123$

## Lexical diffusion, lexical frequency, and lexical analysis

$p=137$

## Exemplar dynamics: Word frequency, lenition and contrast

$p=229$

## Probabilistic relations between words: evidence from reduction in lexical productino